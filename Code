from google.colab import files
uploaded = files.upload()

from zipfile import ZipFile
with ZipFile("parkingdataset.zip", 'r') as zip_ref:
    zip_ref.extractall("/content/images")
print(" Extracted to /content/images")


import os
for root, dirs, files in os.walk("/content/images"):
    print(f"{root} -> {len(files)} files, {len(dirs)} folders")
import shutil
inner_path = "/content/images/parkingdataset"
if os.path.exists(inner_path):
    for item in os.listdir(inner_path):
        shutil.move(os.path.join(inner_path, item), "/content/images/")
    os.rmdir(inner_path)
print(" Moved class folders to /content/images/")


import tensorflow as tf
img_size = (224, 224)
batch_size = 16
dataset = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/images',
    image_size=img_size,
    batch_size=batch_size,
    shuffle=True,
    seed=123,
    validation_split=0.2,
    subset='training'
)

val_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/images',
    image_size=img_size,
    batch_size=batch_size,
    shuffle=True,
    seed=123,
    validation_split=0.2,
    subset='validation'
)

class_names = dataset.class_names
print(" Classes detected:", class_names)

import tensorflow as tf
from tensorflow.keras import layers, models
import matplotlib.pyplot as plt
img_size = (224, 224)
batch_size = 16
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/images',
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=img_size,
    batch_size=batch_size
)
val_ds = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/images',
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=img_size,
    batch_size=batch_size
)
class_names = train_ds.class_names
print("Classes:", class_names)
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
])


model = models.Sequential([
    data_augmentation,
    layers.Rescaling(1./255, input_shape=(224, 224, 3)),

    layers.Conv2D(32, 3, activation='relu'),
    layers.MaxPooling2D(),

    layers.Conv2D(64, 3, activation='relu'),
    layers.MaxPooling2D(),

    layers.Conv2D(128, 3, activation='relu'),
    layers.MaxPooling2D(),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.summary()


epochs = 10
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs
)

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend()
plt.title('Training and Validation Loss')

plt.show()

import numpy as np
from tensorflow.keras.utils import load_img, img_to_array

def predict_parking_image(path):
    img = load_img(path, target_size=img_size)
    img_array = img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)

    prediction = model.predict(img_array)[0][0]
    result = "Occupied" if prediction > 0.5 else "Empty"
    confidence = prediction if prediction > 0.5 else 1 - prediction
    print(f"Prediction: {result} ({confidence*100:.2f}%)")


model.save("smart_parking_model.h5")

import streamlit as st
import tensorflow as tf
from PIL import Image
import numpy as np


st.title("ðŸš— Smart Parking Space Classifier")


@st.cache_resource
def load_model():
    model = tf.keras.models.load_model("smart_parking_model.h5")
    return model

model = load_model()


class_names = ['Available', 'Occupied']


uploaded_file = st.file_uploader("Upload an image of a parking space", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="Uploaded Image", use_column_width=True)


    img_resized = image.resize((224, 224))
    img_array = np.array(img_resized) / 255.0
    img_batch = np.expand_dims(img_array, axis=0)


    prediction = model.predict(img_batch)
    class_index = np.argmax(prediction[0])
    confidence = prediction[0][class_index]

    st.subheader("Prediction:")
    st.write(f"**Class:** {class_names[class_index]}")
    st.write(f"**Confidence:** {confidence:.2f}")


from google.colab import files
files.download("smart_parking_model.h5")


import tensorflow as tf
model = tf.keras.models.load_model('smart_parking_model.h5')
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open('smart_parking_model.tflite', 'wb') as f:
    f.write(tflite_model)


from google.colab import files
files.download('smart_parking_model.tflite')


import tensorflow as tf
import numpy as np
model = tf.keras.models.load_model("smart_parking_model.h5")
def representative_data_gen():
    for _ in range(100):

        dummy_input = np.random.rand(1, 224, 224, 3).astype(np.float32)
        yield [dummy_input]

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
quant_model = converter.convert()
with open("smart_parking_model_int8.tflite", "wb") as f:
    f.write(quant_model)


from google.colab import files
files.download('smart_parking_model_int8.tflite')

import tensorflow as tf
model = tf.keras.models.load_model("smart_parking_model.h5")


from sklearn.metrics import classification_report
import numpy as np
y_true = []
y_pred = []
class_names = val_dataset.class_names
for images, labels in val_dataset:
    preds = model.predict(images)
    preds = tf.where(preds > 0.5, 1, 0)
    y_true.extend(labels.numpy())
    y_pred.extend(preds.numpy().flatten())
print(classification_report(y_true, y_pred, target_names=class_names))


from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras import layers, models

base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')
base_model.trainable = False

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


data_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1)
])


model = tf.keras.Sequential([
    tf.keras.layers.Rescaling(1./255, input_shape=(224, 224, 3)),
    tf.keras.layers.Conv2D(32, 3, activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


from google.colab import files
uploaded = files.upload()


import zipfile
import os
with zipfile.ZipFile("parkingdataset.zip", 'r') as zip_ref:
    zip_ref.extractall("/content/parkingdataset")

train_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/parkingdataset',
    image_size=(224, 224),
    batch_size=32,
    validation_split=0.2,
    subset='training',
    seed=42
)

val_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/parkingdataset',
    image_size=(224, 224),
    batch_size=32,
    validation_split=0.2,
    subset='validation',
    seed=42
)


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
model = keras.Sequential([
    layers.Rescaling(1./255, input_shape=(224, 224, 3)),
    layers.Conv2D(16, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(32, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(64, 3, padding='same', activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])


history = model.fit(train_dataset, validation_data=val_dataset, epochs=10)


import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(len(acc))

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Train Accuracy')
plt.plot(epochs_range, val_acc, label='Val Accuracy')
plt.legend()
plt.title('Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Train Loss')
plt.plot(epochs_range, val_loss, label='Val Loss')
plt.legend()
plt.title('Loss')

plt.show()


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

img_size = (224, 224)
batch_size = 32


train_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/parkingdataset',
    validation_split=0.2,
    subset="training",
    seed=123,
    image_size=img_size,
    batch_size=batch_size
)

val_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/parkingdataset',
    validation_split=0.2,
    subset="validation",
    seed=123,
    image_size=img_size,
    batch_size=batch_size
)


model = keras.Sequential([
    layers.Rescaling(1./255, input_shape=(224, 224, 3)),
    layers.Conv2D(16, 3, activation='relu'),
    layers.MaxPooling2D(),
    layers.Conv2D(32, 3, activation='relu'),
    layers.MaxPooling2D(),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])


model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


history = model.fit(train_dataset, validation_data=val_dataset, epochs=5)


from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True,
    validation_split=0.2
)

train_generator = datagen.flow_from_directory(
    '/content/parkingdataset',
    target_size=img_size,
    batch_size=32,
    class_mode='binary',
    subset='training'
)

val_generator = datagen.flow_from_directory(
    '/content/parkingdataset',
    target_size=img_size,
    batch_size=32,
    class_mode='binary',
    subset='validation'
)


import tensorflow as tf
from tensorflow.keras import layers, models


from tensorflow.keras.preprocessing.image import ImageDataGenerator

img_size = (224, 224)
batch_size = 8

datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=15,
    zoom_range=0.2,
    horizontal_flip=True,
)

train_data = datagen.flow_from_directory(
    '/content/parkingdataset',
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    subset='training',
    shuffle=True
)

val_data = datagen.flow_from_directory(
    '/content/parkingdataset',
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    subset='validation'
)


base_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(train_data, validation_data=val_data, epochs=5)


